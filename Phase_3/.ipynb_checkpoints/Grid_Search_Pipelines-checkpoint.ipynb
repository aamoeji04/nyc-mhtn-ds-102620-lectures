{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop nulls in embarked\n",
    "df.dropna(subset=['embarked','embark_town'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pclass', 'sex','parch', \n",
    "       'embarked', 'class', 'who', 'adult_male', 'embark_town']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the \n",
    "le = LabelEncoder()\n",
    "df.loc[:,cols] = df.loc[:,cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass  sex   age  sibsp  parch     fare  embarked  class  who  \\\n",
       "0           0       2    1  22.0      1      0   7.2500         2      2    1   \n",
       "1           1       0    0  38.0      1      0  71.2833         0      0    2   \n",
       "2           1       2    0  26.0      0      0   7.9250         2      2    2   \n",
       "3           1       0    0  35.0      1      0  53.1000         2      0    2   \n",
       "4           0       2    1  35.0      0      0   8.0500         2      2    1   \n",
       "..        ...     ...  ...   ...    ...    ...      ...       ...    ...  ...   \n",
       "886         0       1    1  27.0      0      0  13.0000         2      1    1   \n",
       "887         1       0    0  19.0      0      0  30.0000         2      0    2   \n",
       "888         0       2    0   NaN      1      2  23.4500         2      2    2   \n",
       "889         1       0    1  26.0      0      0  30.0000         0      0    1   \n",
       "890         0       2    1  32.0      0      0   7.7500         1      2    1   \n",
       "\n",
       "     adult_male deck  embark_town alive  alone  \n",
       "0             1  NaN            2    no  False  \n",
       "1             0    C            0   yes  False  \n",
       "2             0  NaN            2   yes   True  \n",
       "3             0    C            2   yes  False  \n",
       "4             1  NaN            2    no   True  \n",
       "..          ...  ...          ...   ...    ...  \n",
       "886           1  NaN            2    no   True  \n",
       "887           0    B            2   yes   True  \n",
       "888           0  NaN            2    no  False  \n",
       "889           1    C            0   yes   True  \n",
       "890           1  NaN            1    no   True  \n",
       "\n",
       "[889 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and y \n",
    "y = df['survived']\n",
    "X = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
    "       'embarked', 'class', 'who', 'adult_male', 'embark_town']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split the data using stratify to make sure we can get an even split of classes in the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y with even class distributions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/series.py:4523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "#Impute age using the training mean\n",
    "mean_age = X_train.age.mean()\n",
    "X_train['age'].fillna(mean_age, inplace=True)\n",
    "X_test['age'].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = pd.DataFrame(ss.transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(ss.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808988764044944"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8002954791687186"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now with cross validation search\n",
    "val = cross_val_score(RandomForestClassifier(random_state=42),X_train,y_train,cv=5)\n",
    "val.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
    "    \"max_features\": [None,4,5,6,9,10],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 5, 6],\n",
    "    \"n_estimators\" : [10, 30, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = RandomForestClassifier(random_state=42)\n",
    "gridsearch = GridSearchCV(rf_grid, rf_param_grid, cv=5, return_train_score=True, n_jobs=-1, verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3512 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5816 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8696 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10352 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12152 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 14096 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18416 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 20792 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 23312 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 25976 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 29700 out of 29700 | elapsed: 11.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
       "                         'max_features': [None, 4, 5, 6, 9, 10],\n",
       "                         'min_samples_leaf': [1, 2, 3, 5, 6],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 30, 100]},\n",
       "             return_train_score=True, verbose=-1)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 84.11%\n",
      "\n",
      "Optimal Parameters: {'criterion': 'gini', 'max_depth': 10, 'max_features': 5, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "Best Model: RandomForestClassifier(max_depth=10, max_features=5, min_samples_leaf=3,\n",
      "                       min_samples_split=10, n_estimators=10, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy: {:.4}%\".format(gridsearch.best_score_ * 100))\n",
    "print(\"\")\n",
    "print(\"Optimal Parameters: {}\".format(gridsearch.best_params_))\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(\"Best Model: {}\".format(gridsearch.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8089887640449438"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29700"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV * Number of params to search\n",
    "5*2*11*6*3*5*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/series.py:4523: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "# Split X and y with even class distributions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)\n",
    "\n",
    "#Impute age using the training mean\n",
    "mean_age = X_train.age.mean()\n",
    "X_train['age'].fillna(mean_age, inplace=True)\n",
    "X_test['age'].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our pipeline by passing a list of tuples with each class and its name in a string\n",
    "pipeline1 = Pipeline([\n",
    "                    ('ss',StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier(random_state=42))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808988764044944"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the training data to pipeline\n",
    "pipeline1.fit(X_train,y_train)\n",
    "\n",
    "# Print the accuracy on test set\n",
    "pipeline1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "                    ('ss',StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier(random_state=42))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the params, but we add a rf__ to each parameter to let it know its on the rf part of the pipeline\n",
    "rf_param_grid_pipe = {\n",
    "    \"rf__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"rf__max_depth\": [None, 2, 3, 4, 5, 6, 8, 10, 12, 14, 16],\n",
    "    \"rf__max_features\": [None,4,5,6,9,10],\n",
    "    \"rf__min_samples_split\": [2, 5, 10],\n",
    "    \"rf__min_samples_leaf\" : [1, 2, 3, 5, 6],\n",
    "    \"rf__n_estimators\" : [10, 30, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanstiate the gridsearch pipeline\n",
    "grid_search_pipe = GridSearchCV(pipeline2, rf_param_grid_pipe, cv=5, verbose=1, n_jobs=-1, return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5940 candidates, totalling 29700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 852 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2452 tasks      | elapsed:   52.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3552 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4852 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8052 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9952 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12052 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14352 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 16852 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19552 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 22452 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 25552 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 28852 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 29700 out of 29700 | elapsed: 10.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ss', StandardScaler()),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'rf__criterion': ['gini', 'entropy'],\n",
       "                         'rf__max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 12, 14,\n",
       "                                           16],\n",
       "                         'rf__max_features': [None, 4, 5, 6, 9, 10],\n",
       "                         'rf__min_samples_leaf': [1, 2, 3, 5, 6],\n",
       "                         'rf__min_samples_split': [2, 5, 10],\n",
       "                         'rf__n_estimators': [10, 30, 100]},\n",
       "             return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the grid search to the data\n",
    "grid_search_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8089887640449438"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8411110016743819\n",
      "{'rf__criterion': 'gini', 'rf__max_depth': 10, 'rf__max_features': 5, 'rf__min_samples_leaf': 3, 'rf__min_samples_split': 10, 'rf__n_estimators': 10}\n",
      "Pipeline(steps=[('ss', StandardScaler()),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(max_depth=10, max_features=5,\n",
      "                                        min_samples_leaf=3,\n",
      "                                        min_samples_split=10, n_estimators=10,\n",
      "                                        random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid_search_pipe.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid_search_pipe.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid_search_pipe.best_estimator_)\n",
    "#Identify the best score during fitting with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "#Predictions with grid search\n",
    "#Predict the response for test dataset\n",
    "y_pred = grid_search_pipe.best_estimator_.predict(X_test)\n",
    "\n",
    "# Model F1, how often is the classifier correct?\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling the best Estimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle list object\n",
    " \n",
    "model_pickle_path = 'best_model.pkl'\n",
    "\n",
    "#Create a variable to pickle and open it in write mode\n",
    "model_pickle = open(model_pickle_path, 'wb')\n",
    "pickle.dump(grid_search_pipe.best_estimator_, model_pickle)\n",
    "model_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Search\n",
    "\n",
    "Randomized Search allows us to search a distribution for each parameter instead of only a desginated value like GridSearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2.195254015709299, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "#Load in the Iris Dataset and the LogisticRegression class\n",
    "iris = load_iris()\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=0)\n",
    "# Set a distribution and options for the different parameters\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])\n",
    "#Fit and check the best parameters\n",
    "clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
    "search = clf.fit(iris.data, iris.target)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.score(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "- [RandomSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) (Documentation)\n",
    "\n",
    "- [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearch#sklearn.model_selection.GridSearchCV) (Documentation)\n",
    "\n",
    "- [Pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) (Documentation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
